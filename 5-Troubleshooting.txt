GENERAL DEBUGGING
-----------------
Kubectl logs <podname> view logs
kubectl get events 

 If there’s a problem with the scheduler, it could prevent Pods from being scheduled. You can check the scheduler’s logs with the 
kubectl logs <scheduler-pod-name> -n kube-system 


check events
check pod logs
check scheduler pod logs
check node affinity taint and tolerations pvc image name 


PENDING STATE
-------------
“Pending” status for a Pod means that the Pod has been accepted by the K8s system, but it hasn’t been scheduled for running on a node yet
REASONS
- resource crunch
- taint and tolerations
- node affinity
- pvc : if pod is dependent on PV and the pv is not ready 
- Kubescheduler ka pod that is on master node is not running


CRASH LOOP BACK
---------------
Resource cruch not
Locked file/database/port—a resource already locked by another container
Liveness probes– Liveness probes could have misconfigured or probe fails due to any reason.

ImagePullBackOff
---------------
Image is not defined properly - check events usme aa jaega FailedtoPullImage / could be either from a typo or Image may private -> failure - Private Image Registry and Wrong Credentials
Network Issue - POD Not able to pull image due to network issue port blocked on security group
Conatiner Registry Rate Limits - some registries have implimented rate limits

PVC Trouble shooting
--------------------
Following three issues can occur
Persistent Volume creation issue: Kubernetes had a problem creating the persistent volume or enabling access to it, even though the underlying storage resources exist.
Persistent Volume provisioning issue: Kubernetes could not create the required persistent volume because storage resources were unavailable.
Changes in specs: Kubernetes had a problem connecting a pod to the required Persistent Volume because of a configuration change in the PV or PVC.

Reasons - kubectl describe pod podname karoge to dikhega ye error events me
FailedAttachVolume - pichle node se detach hoke ye wale node pe attach nahi ho paa rahi hai Volume
FailedMount - Jab volume mount nahi ho paegi right path pe Agar FailedAttachVolume aega matlb ye bi ana hai 
CrashLoopBackOff caused by PersistentVolume Claim - 

Since Kubernetes can’t automatically handle the FailedAttachVolume and FailedMount errors on its own, sometimes you have to take manual steps.

Other Disk Related Issues in Kubernetes

"node file sytem filling up" - Extend EBS size/Clear data/docker system prune/docker system prune -a
"persistent volume filling up" - Expand PVC by editing Yaml/only gp2 class ka expand hota hai/allow volume expansion =true


POD STATUS:
----------

Pending: This state shows at least one container within the pod has not yet been created.
Running: All containers have been created, and the pod has been bound to a Node. At this point, the containers are running, or are being started or restarted.
Succeeded: All containers in the pod have been successfully terminated and will not be restarted.
Failed: All containers have been terminated, and at least one container has failed. The failed container exists in a non-zero state.
Unknown: The status of the pod cannot be obtained.
